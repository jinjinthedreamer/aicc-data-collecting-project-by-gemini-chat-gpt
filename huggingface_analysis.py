import os
import pandas as pd
from huggingface_hub import InferenceClient
from dotenv import load_dotenv

# ================================
# 1. .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë”©
# ================================
load_dotenv("API_KEY.env")
HF_TOKEN = os.getenv("HUGGING_FACE_HUB_TOKEN")

if not HF_TOKEN:
    raise ValueError("âŒ Hugging Face API í‚¤ë¥¼ .env íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!")

# ================================
# 2. ëª¨ë¸ ì„¤ì • (ë¬´ë£Œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸)
# ================================
client = InferenceClient(
    model="NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",  # âœ… ë¬´ë£Œë¡œ ì•ˆì •ì ì¸ ëª¨ë¸
    token=HF_TOKEN
)

# ================================
# 3. ì±—ë´‡ ë¡œê·¸ ë°ì´í„° ë¶„ì„
# ================================
try:w
    logs = pd.read_csv("chatbot_logs.csv")
    handover_rate = logs["handover"].mean()
    print(f"\nğŸ“Š Human Handover Rate: {handover_rate:.2%}")
    
    prompt_logs = f"""
ì•„ë˜ëŠ” ì±—ë´‡ ëŒ€í™” ë¡œê·¸ì˜ í†µê³„ì…ë‹ˆë‹¤:
- ì´ ëŒ€í™” ìˆ˜: {len(logs)}
- ì¸ê°„ ì´ê´€ ë¹„ìœ¨: {handover_rate:.2%}

1) ì´ ì§€í‘œê°€ ì˜ë¯¸í•˜ëŠ” ë°”ë¥¼ ê¸°íšì ê´€ì ì—ì„œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
2) ê°œì„ ì„ ìœ„í•œ 3ê°€ì§€ ì œì•ˆì„ í•´ì£¼ì„¸ìš”.
"""
    response_logs = client.chat_completion(
        messages=[{"role": "user", "content": prompt_logs}],
        temperature=0.7,
        max_tokens=500
    )
    print("\nğŸ“ˆ ì±—ë´‡ ë¡œê·¸ ë¶„ì„ ìš”ì•½:")
    print(response_logs.choices[0].message["content"])

except Exception as e:
    print("\nâš ï¸ ì±—ë´‡ ë¡œê·¸ ë¶„ì„ ì‹¤íŒ¨:", e)

# ================================
# 4. í†µí™” ë…¹ì·¨ ë¶„ì„
# ================================
try:
    with open("call_transcript.txt", "r", encoding="utf-8") as f:
        transcript = f.read()

    prompt_transcript = f"""
ë‹¤ìŒì€ ê³ ê° í†µí™” ë…¹ì·¨ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•œ ë‚´ìš©ì…ë‹ˆë‹¤:
\"\"\"{transcript[:1000]}...\"\"\"

1) ê³ ê°ì˜ ì£¼ìš” ë¶ˆë§Œ/ìš”êµ¬ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
2) í•´ë‹¹ ì´ìŠˆë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì–´ë–¤ ê¸°ëŠ¥ ë˜ëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼ ê¸°íší•  ìˆ˜ ìˆì„ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”.
"""
    response_transcript = client.chat_completion(
        messages=[{"role": "user", "content": prompt_transcript}],
        temperature=0.7,
        max_tokens=500
    )
    print("\nğŸ“ í†µí™” ë¶„ì„ ê²°ê³¼:")
    print(response_transcript.choices[0].message["content"])

except Exception as e:
    print("\nâš ï¸ í†µí™” ë…¹ì·¨ ë¶„ì„ ì‹¤íŒ¨:", e)

# ================================
# 5. PPT ìŠ¬ë¼ì´ë“œìš© ìš”ì•½ ìƒì„±
# ================================
try:
    ppt_prompt = """
ìœ„ì—ì„œ ì–»ì€ ì œì•ˆ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, 
PPT í•œ ìŠ¬ë¼ì´ë“œ ë¶„ëŸ‰ì˜ ë§ˆí¬ë‹¤ìš´ í˜•ì‹(ì œëª© + í•µì‹¬ 3ê°œ bullet)ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.
"""
    response_ppt = client.chat_completion(
        messages=[{"role": "user", "content": ppt_prompt}],
        temperature=0.7,
        max_tokens=300
    )
    print("\nğŸ–¼ PPT ìŠ¬ë¼ì´ë“œìš© ë§ˆí¬ë‹¤ìš´:")
    print(response_ppt.choices[0].message["content"])

except Exception as e:
    print("\nâš ï¸ PPT ìš”ì•½ ìƒì„± ì‹¤íŒ¨:", e)


#í…ŒìŠ¤íŠ¸ ë°ì´í„° ë° API í‚¤ í™œìš© ì‹œ, í™œìš©ê°€ëŠ¥